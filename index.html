<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Emotide Radio - Real Perspective API</title>
    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Configure Tailwind for the "Inter" font -->
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    fontFamily: {
                        sans: ['Inter', 'sans-serif'],
                    },
                    colors: {
                        'primary': '#0f172a',
                        'secondary': '#1e293b',
                        'accent': '#f97316',
                        'neutral-light': '#f1f5f9'
                    }
                }
            }
        }
    </script>
    <style>
        /* Custom styles for a polished look */
        .card {
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
            transition: transform 0.3s ease;
        }
        .card:hover {
            transform: translateY(-2px);
        }
        .toxicity-bar {
            transition: width 0.5s ease-out;
        }
        .pulse-text {
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }
    </style>
</head>
<body class="bg-neutral-light min-h-screen flex items-center justify-center p-4 font-sans">

    <div id="app" class="w-full max-w-xl bg-white card rounded-xl p-8">
        <h1 class="text-3xl font-bold text-primary mb-2 text-center">
            Emotide Radio üìª
        </h1>
        <p class="text-center text-gray-500 mb-8">
            Paste social media text to filter for toxicity using the Perspective API.
        </p>

        <!-- API Key Warning/Input -->
        <div id="api-key-warning" class="p-4 mb-6 bg-red-100 border border-red-400 text-red-700 rounded-lg hidden">
            <p class="font-semibold">‚ö†Ô∏è API Key Required</p>
            <p class="text-sm">Please update the `PERSPECTIVE_API_KEY` variable in the script with your actual key to enable real analysis.</p>
        </div>

        <!-- Text Input Area -->
        <div class="mb-6">
            <label for="text-input" class="block text-sm font-medium text-gray-700 mb-2">Text to Analyze (Paste Tweet/Comment):</label>
            <textarea id="text-input" rows="4" class="w-full p-3 border-2 border-gray-300 rounded-lg focus:ring-accent focus:border-accent resize-none transition duration-150" placeholder="e.g., 'This is the worst opinion I have ever read.'"></textarea>
        </div>

        <!-- Analyze Button -->
        <button id="analyze-button" class="w-full bg-accent text-white font-semibold py-3 rounded-lg hover:bg-orange-600 transition duration-150 transform hover:scale-[1.01] focus:outline-none focus:ring-4 focus:ring-orange-300 disabled:bg-gray-400 disabled:cursor-not-allowed" onclick="analyzeText()">
            Analyze Sentiment
        </button>

        <!-- Result Display Area -->
        <div id="result-area" class="mt-8 p-6 bg-secondary text-white rounded-lg hidden">
            <h2 class="text-xl font-semibold mb-4 border-b border-gray-600 pb-2">Analysis Result</h2>
            
            <div id="loading-state" class="text-center pulse-text hidden">
                <p>Analyzing text with Perspective API...</p>
                <div class="w-8 h-8 border-4 border-white border-t-transparent rounded-full animate-spin mx-auto mt-3"></div>
            </div>

            <div id="score-display">
                <p class="text-sm font-medium mb-1">Toxicity Score:</p>
                <div class="flex items-center space-x-3 mb-4">
                    <p id="toxicity-value" class="text-2xl font-bold text-accent">--</p>
                    <span id="toxicity-label" class="text-sm rounded-full px-3 py-1 font-medium bg-gray-700"></span>
                </div>
                
                <div class="w-full bg-gray-600 rounded-full h-3">
                    <div id="toxicity-meter" class="toxicity-bar h-3 rounded-full bg-red-500" style="width: 0%;"></div>
                </div>

                <p id="analysis-message" class="mt-4 text-lg font-medium"></p>
            </div>
        </div>
    </div>

    <script>
        // --- API CONFIGURATION ---
        // IMPORTANT: Replace the empty quotes below with your actual Google Perspective API Key.
        // The key MUST be surrounded by double quotes (e.g., "YOUR_API_KEY_HERE") to be treated as a string!
        const PERSPECTIVE_API_KEY = "AIzaSyAro4IIVXjuZ-u02J641xhTQAztWQq9fcY"; 
        const PERSPECTIVE_API_URL = "https://commentanalyzer.googleapis.com/v1alpha1/comments:analyze";
        const MAX_RETRIES = 3;

        // Utility to display messages
        const ui = {
            resultArea: document.getElementById('result-area'),
            loadingState: document.getElementById('loading-state'),
            scoreDisplay: document.getElementById('score-display'),
            toxicityValue: document.getElementById('toxicity-value'),
            toxicityMeter: document.getElementById('toxicity-meter'),
            toxicityLabel: document.getElementById('toxicity-label'),
            analysisMessage: document.getElementById('analysis-message'),
            analyzeButton: document.getElementById('analyze-button'),
            apiKeyWarning: document.getElementById('api-key-warning'),
        };

        // --- AUTH CHECK ---
        document.addEventListener('DOMContentLoaded', () => {
            if (!PERSPECTIVE_API_KEY) {
                ui.apiKeyWarning.classList.remove('hidden');
            }
        });

        /**
         * Real API call to the Google Perspective API with exponential backoff.
         * @param {string} text The comment text to analyze.
         * @returns {Promise<number>} The toxicity probability score (0.0 to 1.0).
         */
        async function fetchPerspectiveScore(text) {
            if (!PERSPECTIVE_API_KEY) {
                // Fallback to mock if key is missing (for local testing without a key)
                console.warn("Using mock API call. Please set PERSPECTIVE_API_KEY for real results.");
                return mockPerspectiveApi();
            }

            const payload = {
                comment: {
                    text: text
                },
                languages: ["en"],
                requestedAttributes: {
                    // We are only interested in general toxicity for Emotide Radio
                    TOXICITY: {} 
                },
                // Crucial for user data privacy: do not store the comment
                doNotStore: true
            };

            const apiUrlWithKey = `${PERSPECTIVE_API_URL}?key=${PERSPECTIVE_API_KEY}`;

            for (let i = 0; i < MAX_RETRIES; i++) {
                try {
                    const response = await fetch(apiUrlWithKey, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify(payload)
                    });

                    if (response.status === 429) {
                        // Too Many Requests - hit rate limit
                        if (i < MAX_RETRIES - 1) {
                            const delay = Math.pow(2, i) * 1000; // Exponential backoff: 1s, 2s, 4s...
                            console.log(`Rate limit hit. Retrying in ${delay / 1000}s...`);
                            await new Promise(resolve => setTimeout(resolve, delay));
                            continue; // Retry the loop
                        } else {
                            throw new Error("API rate limit exceeded after multiple retries.");
                        }
                    }

                    if (!response.ok) {
                        const errorBody = await response.json();
                        throw new Error(`API Error ${response.status}: ${errorBody.error.message}`);
                    }

                    const data = await response.json();
                    
                    // Extract the core toxicity score
                    const score = data.attributeScores?.TOXICITY?.summaryScore?.value;

                    if (typeof score === 'number') {
                        return score; // Success! Return the score
                    } else {
                        throw new Error("Failed to parse toxicity score from API response.");
                    }

                } catch (error) {
                    console.error(`Attempt ${i + 1} failed:`, error.message);
                    if (i === MAX_RETRIES - 1) {
                        // Last attempt failed
                        throw new Error("Perspective API call failed after all retries. Check console for details.");
                    }
                    // Wait before retrying (only if not the last attempt)
                    const delay = Math.pow(2, i) * 1000; // Exponential backoff
                    await new Promise(resolve => setTimeout(resolve, delay));
                }
            }
        }
        
        /**
         * Mock function (used only if API key is missing)
         * @returns {Promise<number>} A random toxicity score.
         */
        function mockPerspectiveApi() {
            return new Promise(resolve => {
                setTimeout(() => {
                    resolve(Math.random()); // Return a random number between 0 and 1
                }, 1500); // Simulate network latency
            });
        }

        // --- UI & LOGIC HANDLER ---

        /**
         * Main function to analyze the text and update the UI.
         */
        async function analyzeText() {
            const textInput = document.getElementById('text-input').value.trim();
            if (!textInput) {
                alertUser('Please enter some text to analyze.', 'error');
                return;
            }

            // 1. Show loading state and disable button
            ui.resultArea.classList.remove('hidden');
            ui.scoreDisplay.classList.add('hidden');
            ui.loadingState.classList.remove('hidden');
            ui.analyzeButton.disabled = true;

            try {
                // 2. Call the real API function
                const score = await fetchPerspectiveScore(textInput);
                
                // 3. Update UI with the result
                displayResult(score);

            } catch (error) {
                // 4. Handle errors and show a user message
                displayError(`Analysis failed: ${error.message}`);
            } finally {
                // 5. Hide loading state and re-enable button
                ui.loadingState.classList.add('hidden');
                ui.analyzeButton.disabled = false;
            }
        }

        /**
         * Updates the UI based on the toxicity score.
         * @param {number} score The toxicity probability (0.0 to 1.0).
         */
        function displayResult(score) {
            ui.scoreDisplay.classList.remove('hidden');
            ui.toxicityValue.textContent = (score * 100).toFixed(1) + '%';
            ui.toxicityMeter.style.width = `${score * 100}%`;

            let label = '';
            let color = '';
            let message = '';

            if (score >= 0.8) {
                label = 'HIGH RISK';
                color = 'bg-red-500';
                message = "üö® Filter engaged. The content is highly toxic and would be blocked or heavily modulated.";
            } else if (score >= 0.5) {
                label = 'MODERATE';
                color = 'bg-yellow-500';
                message = "‚ö†Ô∏è Caution. The content shows moderate toxicity and requires filtering or human review.";
            } else if (score >= 0.2) {
                label = 'LOW';
                color = 'bg-orange-400';
                message = "üôÇ Clean. The content is generally safe but carries a small risk.";
            } else {
                label = 'VERY LOW';
                color = 'bg-green-500';
                message = "‚úÖ Clear. The content is safe for broadcasting.";
            }

            ui.toxicityValue.style.color = color.replace('bg-', 'text-');
            ui.toxicityMeter.className = `toxicity-bar h-3 rounded-full ${color}`;
            ui.toxicityLabel.textContent = label;
            ui.toxicityLabel.className = `text-sm rounded-full px-3 py-1 font-medium ${color} text-white`;
            ui.analysisMessage.textContent = message;
        }

        /**
         * Displays a general error message to the user.
         * @param {string} message The error text.
         */
        function displayError(message) {
            ui.scoreDisplay.classList.remove('hidden');
            ui.toxicityValue.textContent = 'N/A';
            ui.toxicityMeter.style.width = '0%';
            ui.toxicityLabel.textContent = 'ERROR';
            ui.toxicityLabel.className = `text-sm rounded-full px-3 py-1 font-medium bg-gray-500 text-white`;
            ui.analysisMessage.textContent = message;
            ui.toxicityValue.style.color = 'text-gray-500';
            console.error(message);
        }

        /**
         * Custom alert for the user (replaces browser's alert).
         * @param {string} message 
         * @param {string} type 
         */
        function alertUser(message, type) {
            // In a real app, this would be a modal. For simplicity, we use the console/UI.
            console.error(`User Alert [${type}]: ${message}`);
            // You could temporarily show the message in the result area here.
            displayError(message);
        }

    </script>
</body>
</html>
